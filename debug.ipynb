{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import generator\n",
    "import discriminator\n",
    "import helpers\n",
    "\n",
    "\n",
    "CUDA = False\n",
    "VOCAB_SIZE = 15000\n",
    "MAX_SEQ_LEN = 40\n",
    "START_LETTER = 0\n",
    "BATCH_SIZE = 32\n",
    "MLE_TRAIN_EPOCHS = 10\n",
    "ADV_TRAIN_EPOCHS = 5\n",
    "POS_NEG_SAMPLES = 100000\n",
    "\n",
    "GEN_EMBEDDING_DIM = 32\n",
    "GEN_HIDDEN_DIM = 32\n",
    "DIS_EMBEDDING_DIM = 64\n",
    "DIS_HIDDEN_DIM = 64\n",
    "\n",
    "oracle_samples_path = './oracle_samples.trc'\n",
    "oracle_state_dict_path = './oracle_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_gen_path = './gen_MLEtrain_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_dis_path = './dis_pretrain_EMBDIM_64_HIDDENDIM64_VOCAB5000_MAXSEQLEN20.trc'\n",
    "\n",
    "\n",
    "def train_generator_MLE(gen, gen_opt, real_data_samples, epochs):\n",
    "    \"\"\"\n",
    "    Max Likelihood Pretraining for the generator\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch %d : ' % (epoch + 1), end='')\n",
    "        sys.stdout.flush()\n",
    "        total_loss = 0\n",
    "\n",
    "        for i in range(0, POS_NEG_SAMPLES, BATCH_SIZE):\n",
    "            inp, target = helpers.prepare_generator_batch(real_data_samples[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
    "                                                          gpu=CUDA)\n",
    "            gen_opt.zero_grad()\n",
    "            loss = gen.batchNLLLoss(inp, target)\n",
    "            loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "            total_loss += loss.data.item()\n",
    "\n",
    "            if (i / BATCH_SIZE) % ceil(\n",
    "                            ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
    "                print('.', end='')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        # each loss in a batch is loss per sample\n",
    "        total_loss = total_loss / ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
    "\n",
    "\n",
    "        print(' average_train_NLL = %.4f' % (total_loss))\n",
    "\n",
    "\n",
    "def train_generator_PG(gen, gen_opt, validation_data_samples, dis, num_batches):\n",
    "    \"\"\"\n",
    "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
    "    Training is done for num_batches batches.\n",
    "    \"\"\"\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        s = gen.sample(BATCH_SIZE*2)        # 64 works best\n",
    "        inp, target = helpers.prepare_generator_batch(s, start_letter=START_LETTER, gpu=CUDA)\n",
    "        rewards = dis.batchClassify(target)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        pg_loss = gen.batchPGLoss(inp, target, rewards)\n",
    "        pg_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "    validation_loss=0\n",
    "    VAL_SIZE=validation_data_samples.shape[0]\n",
    "    for i in range(0, VAL_SIZE, BATCH_SIZE):\n",
    "        inp, target = helpers.prepare_generator_batch(validation_data_samples[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
    "                                                      gpu=CUDA)\n",
    "        gen_opt.zero_grad()\n",
    "        loss = gen.batchNLLLoss(inp, target)\n",
    "        validation_loss+= loss\n",
    "    #helpers.batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
    "                   #                                start_letter=START_LETTER, gpu=CUDA)\n",
    "\n",
    "    print(' validation_loss = %.4f' % validation_loss)\n",
    "\n",
    "\n",
    "def train_discriminator(discriminator, dis_opt, real_data_samples, generator, trainset, d_steps, epochs):\n",
    "    \"\"\"\n",
    "    Training the discriminator on real_data_samples (positive) and generated samples from generator (negative).\n",
    "    Samples are drawn d_steps times, and the discriminator is trained for epochs epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    # generating a small validation set before training (using oracle and generator)\n",
    "    len_sampled=10\n",
    "    perm=np.random.permutation(trainset.shape[0])\n",
    "    pos_val=torch.tensor(trainset[perm[:len_sampled]])\n",
    "    neg_val = generator.sample(len_sampled)\n",
    "    val_inp, val_target = helpers.prepare_discriminator_data(pos_val, neg_val, gpu=CUDA)\n",
    "\n",
    "    for d_step in range(d_steps):\n",
    "        s = helpers.batchwise_sample(generator, POS_NEG_SAMPLES, BATCH_SIZE)\n",
    "        dis_inp, dis_target = helpers.prepare_discriminator_data(real_data_samples, s, gpu=CUDA)\n",
    "        for epoch in range(epochs):\n",
    "            print('d-step %d epoch %d : ' % (d_step + 1, epoch + 1), end='')\n",
    "            sys.stdout.flush()\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "\n",
    "            for i in range(0, 2 * POS_NEG_SAMPLES, BATCH_SIZE):\n",
    "                inp, target = dis_inp[i:i + BATCH_SIZE], dis_target[i:i + BATCH_SIZE]\n",
    "                dis_opt.zero_grad()\n",
    "                out = discriminator.batchClassify(inp)\n",
    "                loss_fn = nn.BCELoss()\n",
    "                loss = loss_fn(out, target)\n",
    "                loss.backward()\n",
    "                dis_opt.step()\n",
    "\n",
    "                total_loss += loss.data.item()\n",
    "                total_acc += torch.sum((out>0.5)==(target>0.5)).data.item()\n",
    "\n",
    "                if (i / BATCH_SIZE) % ceil(ceil(2 * POS_NEG_SAMPLES / float(\n",
    "                        BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
    "                    print('.', end='')\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "            total_loss /= ceil(2 * POS_NEG_SAMPLES / float(BATCH_SIZE))\n",
    "            total_acc /= float(2 * POS_NEG_SAMPLES)\n",
    "\n",
    "            val_pred = discriminator.batchClassify(val_inp)\n",
    "            print(' average_loss = %.4f, train_acc = %.4f, val_acc = %.4f' % (\n",
    "                total_loss, total_acc, torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/200.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filepath):\n",
    "    ret=[]\n",
    "    with open(filepath,'r') as fin:\n",
    "        for line in fin:\n",
    "            ret.append([int(token) for token in line.split()])\n",
    "    return np.array(ret)\n",
    "trainset=loadData('./dataset/train.vec')\n",
    "validationset=loadData('./dataset/valid.vec')\n",
    "testset=loadData('./dataset/test.vec')\n",
    "\n",
    "trainset_tensor=torch.tensor(trainset)\n",
    "validationset_tensor=torch.tensor(validationset)\n",
    "oracle=None\n",
    "\n",
    "gen = generator.Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "dis = discriminator.Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "\n",
    "if CUDA:\n",
    "    #oracle = oracle.cuda()\n",
    "    gen = gen.cuda()\n",
    "    dis = dis.cuda()\n",
    "    oracle_samples = oracle_samples.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Generator MLE Training...\n",
      "epoch 1 : ....."
     ]
    }
   ],
   "source": [
    "# GENERATOR MLE TRAINING\n",
    "print('Starting Generator MLE Training...')\n",
    "gen_optimizer = optim.Adam(gen.parameters(), lr=1e-2)\n",
    "train_generator_MLE(gen, gen_optimizer, trainset_tensor, MLE_TRAIN_EPOCHS)\n",
    "\n",
    "# torch.save(gen.state_dict(), pretrained_gen_path)\n",
    "# gen.load_state_dict(torch.load(pretrained_gen_path))\n",
    "\n",
    "# PRETRAIN DISCRIMINATOR\n",
    "print('\\nStarting Discriminator Training...')\n",
    "dis_optimizer = optim.Adagrad(dis.parameters())\n",
    "train_discriminator(dis, dis_optimizer, trainset_tensor, gen, trainset, 50, 3)\n",
    "\n",
    "# torch.save(dis.state_dict(), pretrained_dis_path)\n",
    "# dis.load_state_dict(torch.load(pretrained_dis_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Adversarial Training...\n",
      "\n",
      "Initial Oracle Sample Loss : -1.0000\n",
      "\n",
      "--------\n",
      "EPOCH 1\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  validation_loss = 306.1471\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 1 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 1 epoch 3 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 3 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 1 : .... average_loss = 0.0086, train_acc = 0.9922, val_acc = 0.1000\n",
      "d-step 3 epoch 2 : .... average_loss = 0.0007, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 3 : .... average_loss = 0.0005, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 1 : .... average_loss = 0.0006, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 2 : .... average_loss = 0.0006, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 3 : .... average_loss = 0.0005, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 1 : .... average_loss = 0.0005, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 2 : .... average_loss = 0.0005, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 3 : .... average_loss = 0.0005, train_acc = 1.0000, val_acc = 0.1000\n",
      "\n",
      "--------\n",
      "EPOCH 2\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  validation_loss = 307.8322\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 1 epoch 2 : .... average_loss = 0.0005, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 1 epoch 3 : .... average_loss = 0.0005, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 3 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 3 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 3 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 3 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "\n",
      "--------\n",
      "EPOCH 3\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  validation_loss = 310.1112\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 1 epoch 2 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 1 epoch 3 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 1 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 2 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "\n",
      "--------\n",
      "EPOCH 4\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  validation_loss = 312.7539\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 1 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 1 epoch 3 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 1 : .... average_loss = 0.0010, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 2 : .... average_loss = 0.0007, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 3 : .... average_loss = 0.0007, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 1 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 1 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 2 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 1 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 2 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "\n",
      "--------\n",
      "EPOCH 5\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  validation_loss = 315.5955\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 1 epoch 2 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 1 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 1 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 2 : .... average_loss = 0.0004, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 2 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 1 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 2 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 3 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 1 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 2 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 4 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 1 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 2 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n",
      "d-step 5 epoch 3 : .... average_loss = 0.0003, train_acc = 1.0000, val_acc = 0.1000\n"
     ]
    }
   ],
   "source": [
    "# ADVERSARIAL TRAINING\n",
    "print('\\nStarting Adversarial Training...')\n",
    "oracle_loss = -1 #helpers.batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
    "#                                           start_letter=START_LETTER, gpu=CUDA)\n",
    "print('\\nInitial Oracle Sample Loss : %.4f' % oracle_loss)\n",
    "\n",
    "for epoch in range(ADV_TRAIN_EPOCHS):\n",
    "    print('\\n--------\\nEPOCH %d\\n--------' % (epoch+1))\n",
    "    # TRAIN GENERATOR\n",
    "    print('\\nAdversarial Training Generator : ', end='')\n",
    "    sys.stdout.flush()\n",
    "    train_generator_PG(gen, gen_optimizer, validationset_tensor, dis, 1)\n",
    "\n",
    "    # TRAIN DISCRIMINATOR\n",
    "    print('\\nAdversarial Training Discriminator : ')\n",
    "    train_discriminator(dis, dis_optimizer, trainset_tensor, gen, trainset, 5, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
