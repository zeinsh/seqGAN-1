{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import generator\n",
    "import discriminator\n",
    "import helpers\n",
    "\n",
    "\n",
    "CUDA = True\n",
    "VOCAB_SIZE = 15000\n",
    "MAX_SEQ_LEN = 40\n",
    "START_LETTER = 0\n",
    "BATCH_SIZE = 8\n",
    "MLE_TRAIN_EPOCHS = 10\n",
    "ADV_TRAIN_EPOCHS = 10\n",
    "POS_NEG_SAMPLES = 100000\n",
    "\n",
    "GEN_EMBEDDING_DIM = 300\n",
    "GEN_HIDDEN_DIM = 256\n",
    "DIS_EMBEDDING_DIM = 64\n",
    "DIS_HIDDEN_DIM = 64\n",
    "\n",
    "oracle_samples_path = './oracle_samples.trc'\n",
    "oracle_state_dict_path = './oracle_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_gen_path = './gen_MLEtrain_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_dis_path = './dis_pretrain_EMBDIM_64_HIDDENDIM64_VOCAB5000_MAXSEQLEN20.trc'\n",
    "\n",
    "from tqdm import tqdm\n",
    "def getLength(line):\n",
    "    vec=[int(token) for token in line.split()]\n",
    "    try:\n",
    "        return vec.index(1)\n",
    "    except:\n",
    "        return len(line)\n",
    "def calculatePPL(gen,testpath):\n",
    "    testset=loadData(testpath)\n",
    "    testset_tensor=torch.tensor(testset)\n",
    "\n",
    "    length=[]\n",
    "    with open(testpath,'r') as fin:\n",
    "        for line in fin:\n",
    "            length.append(getLength(line))\n",
    "    length=np.array(length)\n",
    "    \n",
    "    nll_all=[]\n",
    "    TEST_SIZE=testset_tensor.shape[0]\n",
    "    for i in tqdm(range(0, TEST_SIZE)):\n",
    "        inp, target = helpers.prepare_generator_batch(testset_tensor[i:i + 1], start_letter=START_LETTER,\n",
    "                                                              gpu=CUDA)\n",
    "        nll = gen.batchNLLLoss(inp, target)\n",
    "        nll_all.append(float(nll.data.cpu()))\n",
    "    nll_all=np.array(nll_all)\n",
    "\n",
    "    return np.mean(2**(nll_all/length))\n",
    "\n",
    "def train_generator_MLE(gen, gen_opt, real_data_samples, epochs):\n",
    "    \"\"\"\n",
    "    Max Likelihood Pretraining for the generator\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch %d : ' % (epoch + 1), end='')\n",
    "        sys.stdout.flush()\n",
    "        total_loss = 0\n",
    "\n",
    "        for i in range(0, POS_NEG_SAMPLES, BATCH_SIZE):\n",
    "            inp, target = helpers.prepare_generator_batch(real_data_samples[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
    "                                                          gpu=CUDA)\n",
    "            gen_opt.zero_grad()\n",
    "            loss = gen.batchNLLLoss(inp, target)\n",
    "            loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "            total_loss += loss.data.item()\n",
    "\n",
    "            if (i / BATCH_SIZE) % ceil(\n",
    "                            ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
    "                print('.', end='')\n",
    "                sys.stdout.flush()\n",
    "        # Generate LSTM samples\n",
    "        path='output/MSE-{}.samples'.format(epoch)\n",
    "        generateSamples(gen, path)\n",
    "\n",
    "        # each loss in a batch is loss per sample\n",
    "        total_loss = total_loss / ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
    "\n",
    "\n",
    "        print(' average_train_NLL = %.4f' % (total_loss))\n",
    "\n",
    "\n",
    "def train_generator_PG(gen, gen_opt, validation_data_samples, dis, num_batches,_id=0):\n",
    "    \"\"\"\n",
    "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
    "    Training is done for num_batches batches.\n",
    "    \"\"\"\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        s = gen.sample(BATCH_SIZE*2)        # 64 works best\n",
    "        inp, target = helpers.prepare_generator_batch(s, start_letter=START_LETTER, gpu=CUDA)\n",
    "        rewards = dis.batchClassify(target)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        pg_loss = gen.batchPGLoss(inp, target, rewards)\n",
    "        pg_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "    # Generate LSTM samples\n",
    "    path='output/ADV-{}.samples'.format(_id)\n",
    "    generateSamples(gen, path)\n",
    "    \n",
    "    #validation_loss=0\n",
    "    #VAL_SIZE=validation_data_samples.shape[0]\n",
    "    #for i in range(0, VAL_SIZE, BATCH_SIZE):\n",
    "    #    inp, target = helpers.prepare_generator_batch(validation_data_samples[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
    "    #                                                  gpu=CUDA)\n",
    "    #    gen_opt.zero_grad()\n",
    "    #    loss = gen.batchNLLLoss(inp, target)\n",
    "    #    validation_loss+= loss\n",
    "    #helpers.batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
    "                   #                                start_letter=START_LETTER, gpu=CUDA)\n",
    "\n",
    "    # print(' validation_loss = %.4f' % validation_loss)\n",
    "\n",
    "\n",
    "def train_discriminator(discriminator, dis_opt, real_data_samples, generator, trainset, d_steps, epochs):\n",
    "    \"\"\"\n",
    "    Training the discriminator on real_data_samples (positive) and generated samples from generator (negative).\n",
    "    Samples are drawn d_steps times, and the discriminator is trained for epochs epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    # generating a small validation set before training (using oracle and generator)\n",
    "    len_sampled=100\n",
    "    perm=np.random.permutation(trainset.shape[0])\n",
    "    pos_val=torch.tensor(trainset[perm[:len_sampled]])\n",
    "    neg_val = generator.sample(len_sampled)\n",
    "    if CUDA:\n",
    "        pos_val=pos_val.cuda()\n",
    "    val_inp, val_target = helpers.prepare_discriminator_data(pos_val, neg_val, gpu=CUDA)\n",
    "\n",
    "    for d_step in range(d_steps):\n",
    "        s = helpers.batchwise_sample(generator, POS_NEG_SAMPLES, BATCH_SIZE)\n",
    "        dis_inp, dis_target = helpers.prepare_discriminator_data(real_data_samples, s, gpu=CUDA)\n",
    "        for epoch in range(epochs):\n",
    "            print('d-step %d epoch %d : ' % (d_step + 1, epoch + 1), end='')\n",
    "            sys.stdout.flush()\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "\n",
    "            for i in range(0, 2 * POS_NEG_SAMPLES, BATCH_SIZE):\n",
    "                inp, target = dis_inp[i:i + BATCH_SIZE], dis_target[i:i + BATCH_SIZE]\n",
    "                dis_opt.zero_grad()\n",
    "                out = discriminator.batchClassify(inp)\n",
    "                loss_fn = nn.BCELoss()\n",
    "                loss = loss_fn(out, target)\n",
    "                loss.backward()\n",
    "                dis_opt.step()\n",
    "\n",
    "                total_loss += loss.data.item()\n",
    "                total_acc += torch.sum((out>0.5)==(target>0.5)).data.item()\n",
    "\n",
    "                if (i / BATCH_SIZE) % ceil(ceil(2 * POS_NEG_SAMPLES / float(\n",
    "                        BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
    "                    print('.', end='')\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "            total_loss /= ceil(2 * POS_NEG_SAMPLES / float(BATCH_SIZE))\n",
    "            total_acc /= float(2 * POS_NEG_SAMPLES)\n",
    "\n",
    "            val_pred = discriminator.batchClassify(val_inp)\n",
    "            print(' average_loss = %.4f, train_acc = %.4f, val_acc = %.4f' % (\n",
    "                total_loss, total_acc, torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/200.))\n",
    "            \n",
    "from torch import Tensor \n",
    "\n",
    "def generateSamples(gen, path):\n",
    "    with open(path,'w') as fout:\n",
    "        for i in range(10):\n",
    "            samples=gen.sample(1000)\n",
    "            samples=np.array(Tensor.cpu(samples.data))\n",
    "\n",
    "            for i in range(samples.shape[0]):\n",
    "                row=[]\n",
    "                for j in range(samples.shape[1]):\n",
    "                    row.append(str(samples[i][j]))\n",
    "                fout.write(' '.join(row)+'\\n')\n",
    "\n",
    "def loadData(filepath):\n",
    "    ret=[]\n",
    "    with open(filepath,'r') as fin:\n",
    "        for line in fin:\n",
    "            ret.append([int(token) for token in line.split()])\n",
    "    return np.array(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=loadData('./dataset/train.vec')\n",
    "validationset=loadData('./dataset/valid.vec')\n",
    "testset=loadData('./dataset/test.vec')\n",
    "\n",
    "trainset_tensor=torch.tensor(trainset)\n",
    "validationset_tensor=torch.tensor(validationset)\n",
    "oracle=None\n",
    "\n",
    "gen = generator.Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "dis = discriminator.Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "\n",
    "if CUDA:\n",
    "    #oracle = oracle.cuda()\n",
    "    gen = gen.cuda()\n",
    "    dis = dis.cuda()\n",
    "    oracle_samples = trainset_tensor.cuda()\n",
    "    trainset_tensor=trainset_tensor.cuda()\n",
    "    validationset_tensor=validationset_tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Generator MLE Training...\n"
     ]
    }
   ],
   "source": [
    "### debug \n",
    "#MLE_TRAIN_EPOCHS=1\n",
    "#########\n",
    "\n",
    "# GENERATOR MLE TRAINING\n",
    "print('Starting Generator MLE Training...')\n",
    "gen_optimizer = optim.Adam(gen.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Generator MLE Training...\n",
      "epoch 1 : .......... average_train_NLL = 2.4609\n",
      "epoch 2 : .......... average_train_NLL = 2.1950\n",
      "epoch 3 : .......... average_train_NLL = 2.0998\n",
      "epoch 4 : .......... average_train_NLL = 2.0408\n",
      "epoch 5 : .......... average_train_NLL = 1.9996\n",
      "epoch 6 : .......... average_train_NLL = 1.9685\n",
      "epoch 7 : .......... average_train_NLL = 1.9438\n",
      "epoch 8 : .......... average_train_NLL = 1.9234\n",
      "epoch 9 : .......... average_train_NLL = 1.9053\n",
      "epoch 10 : .......... average_train_NLL = 1.8902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator_MLE(gen, gen_optimizer, trainset_tensor, MLE_TRAIN_EPOCHS)\n",
    "\n",
    "torch.save(gen.state_dict(), pretrained_gen_path)\n",
    "gen.load_state_dict(torch.load(pretrained_gen_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.load_state_dict(torch.load(pretrained_gen_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Discriminator Training...\n"
     ]
    }
   ],
   "source": [
    "# PRETRAIN DISCRIMINATOR\n",
    "print('\\nStarting Discriminator Training...')\n",
    "d_steps=10\n",
    "\n",
    "######debug######\n",
    "# d_steps=1\n",
    "############\n",
    "dis_optimizer = optim.Adagrad(dis.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Discriminator Training...\n",
      "d-step 1 epoch 1 : .......... average_loss = 0.6079, train_acc = 0.6789, val_acc = 0.5600\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.5367, train_acc = 0.7324, val_acc = 0.6050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.5011, train_acc = 0.7568, val_acc = 0.6550\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.5060, train_acc = 0.7534, val_acc = 0.7200\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.4889, train_acc = 0.7652, val_acc = 0.7100\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.4753, train_acc = 0.7739, val_acc = 0.7250\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.4792, train_acc = 0.7710, val_acc = 0.6950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.4683, train_acc = 0.7775, val_acc = 0.6900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.4588, train_acc = 0.7827, val_acc = 0.7150\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.4641, train_acc = 0.7818, val_acc = 0.7300\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.4552, train_acc = 0.7872, val_acc = 0.7300\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.4472, train_acc = 0.7923, val_acc = 0.7100\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.4531, train_acc = 0.7876, val_acc = 0.6950\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.4454, train_acc = 0.7921, val_acc = 0.7100\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.4389, train_acc = 0.7961, val_acc = 0.7200\n",
      "d-step 6 epoch 1 : .......... average_loss = 0.4445, train_acc = 0.7929, val_acc = 0.7400\n",
      "d-step 6 epoch 2 : .......... average_loss = 0.4383, train_acc = 0.7966, val_acc = 0.7550\n",
      "d-step 6 epoch 3 : .......... average_loss = 0.4319, train_acc = 0.8004, val_acc = 0.7500\n",
      "d-step 7 epoch 1 : .......... average_loss = 0.4368, train_acc = 0.7985, val_acc = 0.7350\n",
      "d-step 7 epoch 2 : .......... average_loss = 0.4304, train_acc = 0.8017, val_acc = 0.7650\n",
      "d-step 7 epoch 3 : .......... average_loss = 0.4255, train_acc = 0.8050, val_acc = 0.7500\n",
      "d-step 8 epoch 1 : .......... average_loss = 0.4340, train_acc = 0.8006, val_acc = 0.7550\n",
      "d-step 8 epoch 2 : .......... average_loss = 0.4285, train_acc = 0.8035, val_acc = 0.7600\n",
      "d-step 8 epoch 3 : .......... average_loss = 0.4235, train_acc = 0.8065, val_acc = 0.7550\n",
      "d-step 9 epoch 1 : .......... average_loss = 0.4274, train_acc = 0.8043, val_acc = 0.7650\n",
      "d-step 9 epoch 2 : .......... average_loss = 0.4222, train_acc = 0.8073, val_acc = 0.7650\n",
      "d-step 9 epoch 3 : .......... average_loss = 0.4171, train_acc = 0.8101, val_acc = 0.7550\n",
      "d-step 10 epoch 1 : .......... average_loss = 0.4216, train_acc = 0.8087, val_acc = 0.7900\n",
      "d-step 10 epoch 2 : .......... average_loss = 0.4167, train_acc = 0.8112, val_acc = 0.7900\n",
      "d-step 10 epoch 3 : .......... average_loss = 0.4121, train_acc = 0.8137, val_acc = 0.7700\n"
     ]
    }
   ],
   "source": [
    "train_discriminator(dis, dis_optimizer, trainset_tensor, gen, trainset, d_steps, 3)\n",
    "\n",
    "torch.save(dis.state_dict(), pretrained_dis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis.load_state_dict(torch.load(pretrained_dis_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Adversarial Training...\n",
      "\n",
      "--------\n",
      "EPOCH 1\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.4587, train_acc = 0.7859, val_acc = 0.7700\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.4064, train_acc = 0.8174, val_acc = 0.8000\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3890, train_acc = 0.8272, val_acc = 0.8000\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.4132, train_acc = 0.8138, val_acc = 0.7900\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.4006, train_acc = 0.8208, val_acc = 0.8000\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3911, train_acc = 0.8263, val_acc = 0.7950\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.4043, train_acc = 0.8190, val_acc = 0.8050\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3955, train_acc = 0.8249, val_acc = 0.8150\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3875, train_acc = 0.8291, val_acc = 0.8250\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3971, train_acc = 0.8237, val_acc = 0.7950\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3890, train_acc = 0.8286, val_acc = 0.7950\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3821, train_acc = 0.8323, val_acc = 0.8000\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3916, train_acc = 0.8274, val_acc = 0.8200\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3846, train_acc = 0.8317, val_acc = 0.8250\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3784, train_acc = 0.8343, val_acc = 0.8150\n",
      "\n",
      "--------\n",
      "EPOCH 2\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3848, train_acc = 0.8314, val_acc = 0.8200\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3781, train_acc = 0.8350, val_acc = 0.8100\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3726, train_acc = 0.8378, val_acc = 0.8100\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3816, train_acc = 0.8339, val_acc = 0.8400\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3756, train_acc = 0.8374, val_acc = 0.8350\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3703, train_acc = 0.8404, val_acc = 0.8400\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3763, train_acc = 0.8376, val_acc = 0.8300\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3703, train_acc = 0.8396, val_acc = 0.8200\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3656, train_acc = 0.8426, val_acc = 0.8200\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3732, train_acc = 0.8382, val_acc = 0.8350\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3676, train_acc = 0.8406, val_acc = 0.8250\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3626, train_acc = 0.8435, val_acc = 0.8150\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3712, train_acc = 0.8400, val_acc = 0.8350\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3656, train_acc = 0.8427, val_acc = 0.8250\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3610, train_acc = 0.8450, val_acc = 0.8150\n",
      "\n",
      "--------\n",
      "EPOCH 3\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3619, train_acc = 0.8446, val_acc = 0.8100\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3569, train_acc = 0.8478, val_acc = 0.8300\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3521, train_acc = 0.8503, val_acc = 0.8150\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3620, train_acc = 0.8452, val_acc = 0.8400\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3573, train_acc = 0.8475, val_acc = 0.8350\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3529, train_acc = 0.8499, val_acc = 0.8500\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3590, train_acc = 0.8462, val_acc = 0.8550\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3541, train_acc = 0.8490, val_acc = 0.8450\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3495, train_acc = 0.8509, val_acc = 0.8450\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3575, train_acc = 0.8482, val_acc = 0.8450\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3528, train_acc = 0.8498, val_acc = 0.8550\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3488, train_acc = 0.8521, val_acc = 0.8750\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3555, train_acc = 0.8491, val_acc = 0.8600\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3514, train_acc = 0.8506, val_acc = 0.8500\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3474, train_acc = 0.8528, val_acc = 0.8250\n",
      "\n",
      "--------\n",
      "EPOCH 4\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3510, train_acc = 0.8508, val_acc = 0.8000\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3469, train_acc = 0.8533, val_acc = 0.8050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3427, train_acc = 0.8554, val_acc = 0.8050\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3495, train_acc = 0.8519, val_acc = 0.8200\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3445, train_acc = 0.8540, val_acc = 0.8100\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3410, train_acc = 0.8560, val_acc = 0.8250\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3462, train_acc = 0.8540, val_acc = 0.8150\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3418, train_acc = 0.8558, val_acc = 0.8350\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3378, train_acc = 0.8583, val_acc = 0.8350\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3441, train_acc = 0.8550, val_acc = 0.8150\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3402, train_acc = 0.8567, val_acc = 0.8300\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3364, train_acc = 0.8588, val_acc = 0.8200\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3417, train_acc = 0.8560, val_acc = 0.8000\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3370, train_acc = 0.8581, val_acc = 0.8100\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3336, train_acc = 0.8605, val_acc = 0.8050\n",
      "\n",
      "--------\n",
      "EPOCH 5\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3381, train_acc = 0.8584, val_acc = 0.8050\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3340, train_acc = 0.8609, val_acc = 0.8100\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3303, train_acc = 0.8628, val_acc = 0.8250\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3357, train_acc = 0.8592, val_acc = 0.8200\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3314, train_acc = 0.8620, val_acc = 0.8050\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3276, train_acc = 0.8637, val_acc = 0.8100\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3346, train_acc = 0.8611, val_acc = 0.8050\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3304, train_acc = 0.8632, val_acc = 0.7950\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3265, train_acc = 0.8645, val_acc = 0.8250\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3324, train_acc = 0.8611, val_acc = 0.8150\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3282, train_acc = 0.8632, val_acc = 0.8050\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3249, train_acc = 0.8652, val_acc = 0.7950\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3320, train_acc = 0.8616, val_acc = 0.8000\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3277, train_acc = 0.8642, val_acc = 0.8150\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3249, train_acc = 0.8656, val_acc = 0.8000\n",
      "\n",
      "--------\n",
      "EPOCH 6\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3242, train_acc = 0.8662, val_acc = 0.8250\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3198, train_acc = 0.8680, val_acc = 0.8200\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3165, train_acc = 0.8694, val_acc = 0.8350\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3269, train_acc = 0.8658, val_acc = 0.8150\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3225, train_acc = 0.8676, val_acc = 0.8350\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3195, train_acc = 0.8689, val_acc = 0.8350\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3251, train_acc = 0.8658, val_acc = 0.8350\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3214, train_acc = 0.8678, val_acc = 0.8400\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3176, train_acc = 0.8693, val_acc = 0.8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 4 epoch 1 : .......... average_loss = 0.3245, train_acc = 0.8662, val_acc = 0.8400\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3207, train_acc = 0.8685, val_acc = 0.8300\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3171, train_acc = 0.8699, val_acc = 0.8350\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3205, train_acc = 0.8679, val_acc = 0.8300\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3167, train_acc = 0.8700, val_acc = 0.8500\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3129, train_acc = 0.8717, val_acc = 0.8600\n",
      "\n",
      "--------\n",
      "EPOCH 7\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3190, train_acc = 0.8687, val_acc = 0.8250\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3149, train_acc = 0.8708, val_acc = 0.8300\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3115, train_acc = 0.8723, val_acc = 0.8150\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3173, train_acc = 0.8699, val_acc = 0.8150\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3127, train_acc = 0.8719, val_acc = 0.8150\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3096, train_acc = 0.8734, val_acc = 0.8150\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3152, train_acc = 0.8706, val_acc = 0.8250\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3114, train_acc = 0.8726, val_acc = 0.8200\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3078, train_acc = 0.8747, val_acc = 0.8350\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3125, train_acc = 0.8720, val_acc = 0.8250\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3090, train_acc = 0.8736, val_acc = 0.8150\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3053, train_acc = 0.8754, val_acc = 0.8100\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3124, train_acc = 0.8724, val_acc = 0.8250\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3082, train_acc = 0.8749, val_acc = 0.8250\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3051, train_acc = 0.8766, val_acc = 0.8200\n",
      "\n",
      "--------\n",
      "EPOCH 8\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3113, train_acc = 0.8732, val_acc = 0.8300\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3075, train_acc = 0.8753, val_acc = 0.8450\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3043, train_acc = 0.8767, val_acc = 0.8350\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3090, train_acc = 0.8736, val_acc = 0.8400\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3054, train_acc = 0.8757, val_acc = 0.8300\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3022, train_acc = 0.8771, val_acc = 0.8350\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3062, train_acc = 0.8757, val_acc = 0.8500\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3026, train_acc = 0.8778, val_acc = 0.8450\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.2992, train_acc = 0.8792, val_acc = 0.8500\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3067, train_acc = 0.8760, val_acc = 0.8500\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3032, train_acc = 0.8774, val_acc = 0.8400\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.2998, train_acc = 0.8796, val_acc = 0.8450\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3054, train_acc = 0.8768, val_acc = 0.8450\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3021, train_acc = 0.8783, val_acc = 0.8200\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.2989, train_acc = 0.8797, val_acc = 0.8350\n",
      "\n",
      "--------\n",
      "EPOCH 9\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3021, train_acc = 0.8778, val_acc = 0.8050\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.2988, train_acc = 0.8795, val_acc = 0.8150\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.2950, train_acc = 0.8814, val_acc = 0.8400\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3017, train_acc = 0.8786, val_acc = 0.8250\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.2973, train_acc = 0.8807, val_acc = 0.8300\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.2946, train_acc = 0.8827, val_acc = 0.8200\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.2992, train_acc = 0.8795, val_acc = 0.8550\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.2957, train_acc = 0.8814, val_acc = 0.8400\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.2928, train_acc = 0.8828, val_acc = 0.8450\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.2979, train_acc = 0.8804, val_acc = 0.8450\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.2954, train_acc = 0.8815, val_acc = 0.8300\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.2921, train_acc = 0.8835, val_acc = 0.8400\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.2976, train_acc = 0.8803, val_acc = 0.8300\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.2940, train_acc = 0.8822, val_acc = 0.8250\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.2914, train_acc = 0.8833, val_acc = 0.8350\n",
      "\n",
      "--------\n",
      "EPOCH 10\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.2948, train_acc = 0.8814, val_acc = 0.8350\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.2912, train_acc = 0.8836, val_acc = 0.8400\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.2884, train_acc = 0.8848, val_acc = 0.8400\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.2926, train_acc = 0.8831, val_acc = 0.8450\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.2897, train_acc = 0.8847, val_acc = 0.8600\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.2871, train_acc = 0.8859, val_acc = 0.8500\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.2918, train_acc = 0.8840, val_acc = 0.8350\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.2885, train_acc = 0.8852, val_acc = 0.8500\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.2853, train_acc = 0.8867, val_acc = 0.8700\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.2925, train_acc = 0.8833, val_acc = 0.8350\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.2890, train_acc = 0.8853, val_acc = 0.8650\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.2862, train_acc = 0.8864, val_acc = 0.8500\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.2894, train_acc = 0.8849, val_acc = 0.8550\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.2860, train_acc = 0.8869, val_acc = 0.8450\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.2828, train_acc = 0.8878, val_acc = 0.8500\n"
     ]
    }
   ],
   "source": [
    "# ADVERSARIAL TRAINING\n",
    "print('\\nStarting Adversarial Training...')\n",
    "d_steps=5\n",
    "\n",
    "### debug ##\n",
    "# d_step=1####\n",
    "############\n",
    "\n",
    "for epoch in range(ADV_TRAIN_EPOCHS):\n",
    "    print('\\n--------\\nEPOCH %d\\n--------' % (epoch+1))\n",
    "    # TRAIN GENERATOR\n",
    "    print('\\nAdversarial Training Generator : ', end='')\n",
    "    sys.stdout.flush()\n",
    "    train_generator_PG(gen, gen_optimizer, validationset_tensor, dis, 1, _id=epoch)\n",
    "\n",
    "    # TRAIN DISCRIMINATOR\n",
    "    print('\\nAdversarial Training Discriminator : ')\n",
    "    train_discriminator(dis, dis_optimizer, trainset_tensor, gen, trainset, d_steps, 3)\n",
    "    \n",
    "    # Generate seqGAN samples\n",
    "    path='output/seqGAN-epoch{}.samples'.format(epoch)\n",
    "    generateSamples(gen, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqgan_gen_path = './gen_seqgan_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "torch.save(gen.state_dict(), seqgan_gen_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Perplexity On The seqGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15092/15092 [03:20<00:00, 75.16it/s]\n"
     ]
    }
   ],
   "source": [
    "path='./dataset/test.vec'\n",
    "ppl=calculatePPL(gen, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.931168608907385"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Perplexity On The seqGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15092/15092 [03:22<00:00, 74.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.88096423175528"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.load_state_dict(torch.load(pretrained_gen_path))\n",
    "path='./dataset/test.vec'\n",
    "ppl=calculatePPL(gen, path)\n",
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LSTM samples\n",
    "gen.load_state_dict(torch.load(seqgan_gen_path))\n",
    "\n",
    "path='output/seqgan.samples'\n",
    "generateSamples(gen, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
