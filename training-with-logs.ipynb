{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import generator\n",
    "import discriminator\n",
    "import helpers\n",
    "\n",
    "\n",
    "CUDA = True\n",
    "VOCAB_SIZE = 15000\n",
    "MAX_SEQ_LEN = 40\n",
    "START_LETTER = 0\n",
    "BATCH_SIZE = 8\n",
    "MLE_TRAIN_EPOCHS = 10\n",
    "ADV_TRAIN_EPOCHS = 10\n",
    "POS_NEG_SAMPLES = 100000\n",
    "\n",
    "GEN_EMBEDDING_DIM = 300\n",
    "GEN_HIDDEN_DIM = 256\n",
    "DIS_EMBEDDING_DIM = 64\n",
    "DIS_HIDDEN_DIM = 64\n",
    "\n",
    "oracle_samples_path = './oracle_samples.trc'\n",
    "oracle_state_dict_path = './oracle_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_gen_path = './gen_MLEtrain_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_dis_path = './dis_pretrain_EMBDIM_64_HIDDENDIM64_VOCAB5000_MAXSEQLEN20.trc'\n",
    "\n",
    "from tqdm import tqdm\n",
    "def getLength(line):\n",
    "    vec=[int(token) for token in line.split()]\n",
    "    return vec.index(0)\n",
    "def calculatePPL(gen,testpath):\n",
    "    testset=loadData(testpath)\n",
    "    testset_tensor=torch.tensor(testset)\n",
    "\n",
    "    length=[]\n",
    "    with open(testpath,'r') as fin:\n",
    "        for line in fin:\n",
    "            length.append(getLength(line))\n",
    "    length=np.array(length)\n",
    "    \n",
    "    nll_all=[]\n",
    "    TEST_SIZE=testset_tensor.shape[0]\n",
    "    for i in tqdm(range(0, TEST_SIZE)):\n",
    "        inp, target = helpers.prepare_generator_batch(testset_tensor[i:i + 1], start_letter=START_LETTER,\n",
    "                                                              gpu=CUDA)\n",
    "        nll = gen.batchNLLLoss(inp, target)\n",
    "        nll_all.append(float(nll.data.cpu()))\n",
    "    nll_all=np.array(nll_all)\n",
    "\n",
    "    return np.mean(2**(nll_all/length))\n",
    "\n",
    "def train_generator_MLE(gen, gen_opt, real_data_samples, epochs):\n",
    "    \"\"\"\n",
    "    Max Likelihood Pretraining for the generator\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch %d : ' % (epoch + 1), end='')\n",
    "        sys.stdout.flush()\n",
    "        total_loss = 0\n",
    "\n",
    "        for i in range(0, POS_NEG_SAMPLES, BATCH_SIZE):\n",
    "            inp, target = helpers.prepare_generator_batch(real_data_samples[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
    "                                                          gpu=CUDA)\n",
    "            gen_opt.zero_grad()\n",
    "            loss = gen.batchNLLLoss(inp, target)\n",
    "            loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "            total_loss += loss.data.item()\n",
    "\n",
    "            if (i / BATCH_SIZE) % ceil(\n",
    "                            ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
    "                print('.', end='')\n",
    "                sys.stdout.flush()\n",
    "        # Generate LSTM samples\n",
    "        path='output/MSE-{}.samples'.format(epoch)\n",
    "        generateSamples(gen, path)\n",
    "\n",
    "        # each loss in a batch is loss per sample\n",
    "        total_loss = total_loss / ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
    "\n",
    "\n",
    "        print(' average_train_NLL = %.4f' % (total_loss))\n",
    "\n",
    "\n",
    "def train_generator_PG(gen, gen_opt, validation_data_samples, dis, num_batches,_id=0):\n",
    "    \"\"\"\n",
    "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
    "    Training is done for num_batches batches.\n",
    "    \"\"\"\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        s = gen.sample(BATCH_SIZE*2)        # 64 works best\n",
    "        inp, target = helpers.prepare_generator_batch(s, start_letter=START_LETTER, gpu=CUDA)\n",
    "        rewards = dis.batchClassify(target)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        pg_loss = gen.batchPGLoss(inp, target, rewards)\n",
    "        pg_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "    # Generate LSTM samples\n",
    "    path='output/ADV-{}.samples'.format(_id)\n",
    "    generateSamples(gen, path)\n",
    "    \n",
    "    #validation_loss=0\n",
    "    #VAL_SIZE=validation_data_samples.shape[0]\n",
    "    #for i in range(0, VAL_SIZE, BATCH_SIZE):\n",
    "    #    inp, target = helpers.prepare_generator_batch(validation_data_samples[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
    "    #                                                  gpu=CUDA)\n",
    "    #    gen_opt.zero_grad()\n",
    "    #    loss = gen.batchNLLLoss(inp, target)\n",
    "    #    validation_loss+= loss\n",
    "    #helpers.batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
    "                   #                                start_letter=START_LETTER, gpu=CUDA)\n",
    "\n",
    "    # print(' validation_loss = %.4f' % validation_loss)\n",
    "\n",
    "\n",
    "def train_discriminator(discriminator, dis_opt, real_data_samples, generator, trainset, d_steps, epochs):\n",
    "    \"\"\"\n",
    "    Training the discriminator on real_data_samples (positive) and generated samples from generator (negative).\n",
    "    Samples are drawn d_steps times, and the discriminator is trained for epochs epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    # generating a small validation set before training (using oracle and generator)\n",
    "    len_sampled=100\n",
    "    perm=np.random.permutation(trainset.shape[0])\n",
    "    pos_val=torch.tensor(trainset[perm[:len_sampled]])\n",
    "    neg_val = generator.sample(len_sampled)\n",
    "    if CUDA:\n",
    "        pos_val=pos_val.cuda()\n",
    "    val_inp, val_target = helpers.prepare_discriminator_data(pos_val, neg_val, gpu=CUDA)\n",
    "\n",
    "    for d_step in range(d_steps):\n",
    "        s = helpers.batchwise_sample(generator, POS_NEG_SAMPLES, BATCH_SIZE)\n",
    "        dis_inp, dis_target = helpers.prepare_discriminator_data(real_data_samples, s, gpu=CUDA)\n",
    "        for epoch in range(epochs):\n",
    "            print('d-step %d epoch %d : ' % (d_step + 1, epoch + 1), end='')\n",
    "            sys.stdout.flush()\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "\n",
    "            for i in range(0, 2 * POS_NEG_SAMPLES, BATCH_SIZE):\n",
    "                inp, target = dis_inp[i:i + BATCH_SIZE], dis_target[i:i + BATCH_SIZE]\n",
    "                dis_opt.zero_grad()\n",
    "                out = discriminator.batchClassify(inp)\n",
    "                loss_fn = nn.BCELoss()\n",
    "                loss = loss_fn(out, target)\n",
    "                loss.backward()\n",
    "                dis_opt.step()\n",
    "\n",
    "                total_loss += loss.data.item()\n",
    "                total_acc += torch.sum((out>0.5)==(target>0.5)).data.item()\n",
    "\n",
    "                if (i / BATCH_SIZE) % ceil(ceil(2 * POS_NEG_SAMPLES / float(\n",
    "                        BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
    "                    print('.', end='')\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "            total_loss /= ceil(2 * POS_NEG_SAMPLES / float(BATCH_SIZE))\n",
    "            total_acc /= float(2 * POS_NEG_SAMPLES)\n",
    "\n",
    "            val_pred = discriminator.batchClassify(val_inp)\n",
    "            print(' average_loss = %.4f, train_acc = %.4f, val_acc = %.4f' % (\n",
    "                total_loss, total_acc, torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/200.))\n",
    "            \n",
    "from torch import Tensor \n",
    "\n",
    "def generateSamples(gen, path):\n",
    "    with open(path,'w') as fout:\n",
    "        for i in range(10):\n",
    "            samples=gen.sample(1000)\n",
    "            samples=np.array(Tensor.cpu(samples.data))\n",
    "\n",
    "            for i in range(samples.shape[0]):\n",
    "                row=[]\n",
    "                for j in range(samples.shape[1]):\n",
    "                    row.append(str(samples[i][j]))\n",
    "                fout.write(' '.join(row)+'\\n')\n",
    "\n",
    "def loadData(filepath):\n",
    "    ret=[]\n",
    "    with open(filepath,'r') as fin:\n",
    "        for line in fin:\n",
    "            ret.append([int(token) for token in line.split()])\n",
    "    return np.array(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=loadData('./dataset/train.vec')\n",
    "validationset=loadData('./dataset/valid.vec')\n",
    "testset=loadData('./dataset/test.vec')\n",
    "\n",
    "trainset_tensor=torch.tensor(trainset)\n",
    "validationset_tensor=torch.tensor(validationset)\n",
    "oracle=None\n",
    "\n",
    "gen = generator.Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "dis = discriminator.Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "\n",
    "if CUDA:\n",
    "    #oracle = oracle.cuda()\n",
    "    gen = gen.cuda()\n",
    "    dis = dis.cuda()\n",
    "    oracle_samples = trainset_tensor.cuda()\n",
    "    trainset_tensor=trainset_tensor.cuda()\n",
    "    validationset_tensor=validationset_tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Generator MLE Training...\n",
      "epoch 1 : .......... average_train_NLL = 2.2502\n",
      "epoch 2 : .......... average_train_NLL = 1.8927\n",
      "epoch 3 : .......... average_train_NLL = 1.7564\n",
      "epoch 4 : .......... average_train_NLL = 1.6709\n",
      "epoch 5 : .......... average_train_NLL = 1.6097\n",
      "epoch 6 : .......... average_train_NLL = 1.5631\n",
      "epoch 7 : .......... average_train_NLL = 1.5269\n",
      "epoch 8 : .......... average_train_NLL = 1.4970\n",
      "epoch 9 : .......... average_train_NLL = 1.4732\n",
      "epoch 10 : .......... average_train_NLL = 1.4526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### debug \n",
    "#MLE_TRAIN_EPOCHS=1\n",
    "#########\n",
    "\n",
    "# GENERATOR MLE TRAINING\n",
    "print('Starting Generator MLE Training...')\n",
    "gen_optimizer = optim.Adam(gen.parameters(), lr=1e-3)\n",
    "train_generator_MLE(gen, gen_optimizer, trainset_tensor, MLE_TRAIN_EPOCHS)\n",
    "\n",
    "torch.save(gen.state_dict(), pretrained_gen_path)\n",
    "gen.load_state_dict(torch.load(pretrained_gen_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Discriminator Training...\n",
      "d-step 1 epoch 1 : .......... average_loss = 0.6107, train_acc = 0.6757, val_acc = 0.6250\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.5395, train_acc = 0.7298, val_acc = 0.6850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.5034, train_acc = 0.7541, val_acc = 0.7050\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.5108, train_acc = 0.7496, val_acc = 0.7350\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.4935, train_acc = 0.7611, val_acc = 0.7400\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.4797, train_acc = 0.7707, val_acc = 0.7650\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.4868, train_acc = 0.7658, val_acc = 0.7600\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.4751, train_acc = 0.7741, val_acc = 0.7550\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.4659, train_acc = 0.7799, val_acc = 0.7500\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.4715, train_acc = 0.7760, val_acc = 0.7150\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.4625, train_acc = 0.7816, val_acc = 0.7250\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.4549, train_acc = 0.7862, val_acc = 0.7350\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.4604, train_acc = 0.7837, val_acc = 0.7950\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.4526, train_acc = 0.7886, val_acc = 0.7950\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.4458, train_acc = 0.7925, val_acc = 0.7600\n",
      "d-step 6 epoch 1 : .......... average_loss = 0.4505, train_acc = 0.7901, val_acc = 0.7600\n",
      "d-step 6 epoch 2 : .......... average_loss = 0.4436, train_acc = 0.7943, val_acc = 0.7600\n",
      "d-step 6 epoch 3 : .......... average_loss = 0.4377, train_acc = 0.7975, val_acc = 0.7750\n",
      "d-step 7 epoch 1 : .......... average_loss = 0.4434, train_acc = 0.7941, val_acc = 0.7350\n",
      "d-step 7 epoch 2 : .......... average_loss = 0.4372, train_acc = 0.7985, val_acc = 0.7500\n",
      "d-step 7 epoch 3 : .......... average_loss = 0.4318, train_acc = 0.8008, val_acc = 0.7700\n",
      "d-step 8 epoch 1 : .......... average_loss = 0.4389, train_acc = 0.7973, val_acc = 0.7650\n",
      "d-step 8 epoch 2 : .......... average_loss = 0.4329, train_acc = 0.8006, val_acc = 0.7550\n",
      "d-step 8 epoch 3 : .......... average_loss = 0.4281, train_acc = 0.8034, val_acc = 0.7500\n",
      "d-step 9 epoch 1 : .......... average_loss = 0.4339, train_acc = 0.7998, val_acc = 0.7600\n",
      "d-step 9 epoch 2 : .......... average_loss = 0.4290, train_acc = 0.8030, val_acc = 0.7700\n",
      "d-step 9 epoch 3 : .......... average_loss = 0.4240, train_acc = 0.8054, val_acc = 0.7850\n",
      "d-step 10 epoch 1 : .......... average_loss = 0.4317, train_acc = 0.8020, val_acc = 0.7800\n",
      "d-step 10 epoch 2 : .......... average_loss = 0.4264, train_acc = 0.8044, val_acc = 0.7700\n",
      "d-step 10 epoch 3 : .......... average_loss = 0.4221, train_acc = 0.8077, val_acc = 0.7700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRETRAIN DISCRIMINATOR\n",
    "print('\\nStarting Discriminator Training...')\n",
    "d_steps=10\n",
    "\n",
    "######debug######\n",
    "# d_steps=1\n",
    "############\n",
    "dis_optimizer = optim.Adagrad(dis.parameters())\n",
    "train_discriminator(dis, dis_optimizer, trainset_tensor, gen, trainset, d_steps, 3)\n",
    "\n",
    "torch.save(dis.state_dict(), pretrained_dis_path)\n",
    "dis.load_state_dict(torch.load(pretrained_dis_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Adversarial Training...\n",
      "\n",
      "--------\n",
      "EPOCH 1\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.4255, train_acc = 0.8057, val_acc = 0.7600\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.4203, train_acc = 0.8087, val_acc = 0.7700\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.4167, train_acc = 0.8115, val_acc = 0.7800\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.4247, train_acc = 0.8063, val_acc = 0.7800\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.4198, train_acc = 0.8089, val_acc = 0.7850\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.4158, train_acc = 0.8115, val_acc = 0.7750\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.4191, train_acc = 0.8098, val_acc = 0.7700\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.4142, train_acc = 0.8121, val_acc = 0.7600\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.4104, train_acc = 0.8142, val_acc = 0.7800\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.4174, train_acc = 0.8107, val_acc = 0.7750\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.4128, train_acc = 0.8132, val_acc = 0.7600\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.4095, train_acc = 0.8152, val_acc = 0.7800\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.4149, train_acc = 0.8124, val_acc = 0.7750\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.4102, train_acc = 0.8153, val_acc = 0.7850\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.4069, train_acc = 0.8168, val_acc = 0.7700\n",
      "\n",
      "--------\n",
      "EPOCH 2\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.4114, train_acc = 0.8150, val_acc = 0.7200\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.4071, train_acc = 0.8166, val_acc = 0.7200\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.4040, train_acc = 0.8186, val_acc = 0.6950\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.4092, train_acc = 0.8161, val_acc = 0.7400\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.4048, train_acc = 0.8185, val_acc = 0.7450\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.4018, train_acc = 0.8205, val_acc = 0.7300\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.4044, train_acc = 0.8183, val_acc = 0.7300\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.4002, train_acc = 0.8208, val_acc = 0.7300\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3967, train_acc = 0.8229, val_acc = 0.7250\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.4040, train_acc = 0.8203, val_acc = 0.7150\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3999, train_acc = 0.8220, val_acc = 0.7200\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3966, train_acc = 0.8239, val_acc = 0.7300\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.4023, train_acc = 0.8203, val_acc = 0.7250\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3984, train_acc = 0.8225, val_acc = 0.7450\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3948, train_acc = 0.8251, val_acc = 0.7450\n",
      "\n",
      "--------\n",
      "EPOCH 3\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3988, train_acc = 0.8227, val_acc = 0.7900\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3953, train_acc = 0.8246, val_acc = 0.7850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3917, train_acc = 0.8264, val_acc = 0.7850\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3965, train_acc = 0.8246, val_acc = 0.8050\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3923, train_acc = 0.8266, val_acc = 0.8150\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3888, train_acc = 0.8284, val_acc = 0.8050\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3971, train_acc = 0.8231, val_acc = 0.8150\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3931, train_acc = 0.8259, val_acc = 0.8000\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3900, train_acc = 0.8271, val_acc = 0.8100\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3943, train_acc = 0.8255, val_acc = 0.7800\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3912, train_acc = 0.8270, val_acc = 0.7900\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3879, train_acc = 0.8287, val_acc = 0.7950\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3912, train_acc = 0.8276, val_acc = 0.7950\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3877, train_acc = 0.8290, val_acc = 0.7800\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3844, train_acc = 0.8311, val_acc = 0.7850\n",
      "\n",
      "--------\n",
      "EPOCH 4\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3885, train_acc = 0.8293, val_acc = 0.8200\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3850, train_acc = 0.8316, val_acc = 0.8050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3821, train_acc = 0.8328, val_acc = 0.8250\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3904, train_acc = 0.8280, val_acc = 0.8200\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3866, train_acc = 0.8305, val_acc = 0.8100\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3837, train_acc = 0.8321, val_acc = 0.8200\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3856, train_acc = 0.8306, val_acc = 0.7900\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3820, train_acc = 0.8323, val_acc = 0.8200\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3790, train_acc = 0.8338, val_acc = 0.8250\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3868, train_acc = 0.8303, val_acc = 0.8300\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3835, train_acc = 0.8324, val_acc = 0.8100\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3804, train_acc = 0.8344, val_acc = 0.8150\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3863, train_acc = 0.8306, val_acc = 0.8150\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3823, train_acc = 0.8322, val_acc = 0.8150\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3795, train_acc = 0.8341, val_acc = 0.8400\n",
      "\n",
      "--------\n",
      "EPOCH 5\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3821, train_acc = 0.8332, val_acc = 0.7850\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3787, train_acc = 0.8353, val_acc = 0.7950\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3752, train_acc = 0.8372, val_acc = 0.7850\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3826, train_acc = 0.8333, val_acc = 0.7800\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3791, train_acc = 0.8351, val_acc = 0.7850\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3764, train_acc = 0.8362, val_acc = 0.7750\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3827, train_acc = 0.8329, val_acc = 0.8050\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3797, train_acc = 0.8345, val_acc = 0.7900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3765, train_acc = 0.8360, val_acc = 0.7950\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3809, train_acc = 0.8337, val_acc = 0.7900\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3771, train_acc = 0.8362, val_acc = 0.7900\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3741, train_acc = 0.8382, val_acc = 0.7900\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3771, train_acc = 0.8365, val_acc = 0.7950\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3737, train_acc = 0.8380, val_acc = 0.7800\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3708, train_acc = 0.8400, val_acc = 0.7850\n",
      "\n",
      "--------\n",
      "EPOCH 6\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3743, train_acc = 0.8376, val_acc = 0.7950\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3709, train_acc = 0.8397, val_acc = 0.8050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3681, train_acc = 0.8406, val_acc = 0.8000\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3743, train_acc = 0.8387, val_acc = 0.8300\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3710, train_acc = 0.8404, val_acc = 0.8000\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3683, train_acc = 0.8417, val_acc = 0.8150\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3725, train_acc = 0.8392, val_acc = 0.8250\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3689, train_acc = 0.8413, val_acc = 0.8000\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3662, train_acc = 0.8430, val_acc = 0.8250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 4 epoch 1 : .......... average_loss = 0.3724, train_acc = 0.8393, val_acc = 0.8000\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3694, train_acc = 0.8402, val_acc = 0.8000\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3666, train_acc = 0.8419, val_acc = 0.8150\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3717, train_acc = 0.8398, val_acc = 0.8200\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3681, train_acc = 0.8416, val_acc = 0.8150\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3653, train_acc = 0.8431, val_acc = 0.8050\n",
      "\n",
      "--------\n",
      "EPOCH 7\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3704, train_acc = 0.8411, val_acc = 0.8150\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3669, train_acc = 0.8435, val_acc = 0.8000\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3644, train_acc = 0.8446, val_acc = 0.8150\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3685, train_acc = 0.8412, val_acc = 0.8050\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3655, train_acc = 0.8427, val_acc = 0.8000\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3629, train_acc = 0.8441, val_acc = 0.8200\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3674, train_acc = 0.8425, val_acc = 0.8000\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3641, train_acc = 0.8442, val_acc = 0.8050\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3612, train_acc = 0.8456, val_acc = 0.8100\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3650, train_acc = 0.8441, val_acc = 0.8050\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3619, train_acc = 0.8448, val_acc = 0.8050\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3591, train_acc = 0.8466, val_acc = 0.8100\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3680, train_acc = 0.8426, val_acc = 0.7950\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3649, train_acc = 0.8443, val_acc = 0.7900\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3622, train_acc = 0.8457, val_acc = 0.8200\n",
      "\n",
      "--------\n",
      "EPOCH 8\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3637, train_acc = 0.8441, val_acc = 0.7950\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3604, train_acc = 0.8458, val_acc = 0.7800\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3576, train_acc = 0.8473, val_acc = 0.7750\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3623, train_acc = 0.8465, val_acc = 0.7900\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3593, train_acc = 0.8472, val_acc = 0.7900\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3565, train_acc = 0.8484, val_acc = 0.8000\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3617, train_acc = 0.8461, val_acc = 0.8000\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3588, train_acc = 0.8473, val_acc = 0.7900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3562, train_acc = 0.8491, val_acc = 0.7950\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3602, train_acc = 0.8470, val_acc = 0.7950\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3573, train_acc = 0.8483, val_acc = 0.7950\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3542, train_acc = 0.8501, val_acc = 0.7850\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3580, train_acc = 0.8481, val_acc = 0.7800\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3551, train_acc = 0.8497, val_acc = 0.7950\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3522, train_acc = 0.8509, val_acc = 0.7900\n",
      "\n",
      "--------\n",
      "EPOCH 9\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3587, train_acc = 0.8473, val_acc = 0.8100\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3556, train_acc = 0.8489, val_acc = 0.8300\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3533, train_acc = 0.8501, val_acc = 0.8050\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3582, train_acc = 0.8479, val_acc = 0.8250\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3546, train_acc = 0.8506, val_acc = 0.8150\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3522, train_acc = 0.8517, val_acc = 0.8150\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3566, train_acc = 0.8494, val_acc = 0.8150\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3535, train_acc = 0.8513, val_acc = 0.8250\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3509, train_acc = 0.8526, val_acc = 0.8150\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3564, train_acc = 0.8490, val_acc = 0.8400\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3539, train_acc = 0.8506, val_acc = 0.8450\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3512, train_acc = 0.8516, val_acc = 0.8100\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3549, train_acc = 0.8495, val_acc = 0.8250\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3519, train_acc = 0.8512, val_acc = 0.8350\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3495, train_acc = 0.8523, val_acc = 0.8250\n",
      "\n",
      "--------\n",
      "EPOCH 10\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator : \n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.3562, train_acc = 0.8499, val_acc = 0.8600\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.3529, train_acc = 0.8517, val_acc = 0.8550\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.3506, train_acc = 0.8528, val_acc = 0.8650\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.3543, train_acc = 0.8501, val_acc = 0.8450\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.3506, train_acc = 0.8528, val_acc = 0.8400\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.3487, train_acc = 0.8534, val_acc = 0.8450\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.3540, train_acc = 0.8512, val_acc = 0.8700\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.3508, train_acc = 0.8527, val_acc = 0.8650\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.3482, train_acc = 0.8543, val_acc = 0.8450\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.3500, train_acc = 0.8525, val_acc = 0.8500\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.3468, train_acc = 0.8540, val_acc = 0.8550\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.3443, train_acc = 0.8560, val_acc = 0.8650\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.3510, train_acc = 0.8518, val_acc = 0.8650\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.3485, train_acc = 0.8534, val_acc = 0.8550\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.3454, train_acc = 0.8545, val_acc = 0.8650\n"
     ]
    }
   ],
   "source": [
    "# ADVERSARIAL TRAINING\n",
    "print('\\nStarting Adversarial Training...')\n",
    "d_steps=5\n",
    "\n",
    "### debug ##\n",
    "# d_step=1####\n",
    "############\n",
    "\n",
    "for epoch in range(ADV_TRAIN_EPOCHS):\n",
    "    print('\\n--------\\nEPOCH %d\\n--------' % (epoch+1))\n",
    "    # TRAIN GENERATOR\n",
    "    print('\\nAdversarial Training Generator : ', end='')\n",
    "    sys.stdout.flush()\n",
    "    train_generator_PG(gen, gen_optimizer, validationset_tensor, dis, 1, _id=epoch)\n",
    "\n",
    "    # TRAIN DISCRIMINATOR\n",
    "    print('\\nAdversarial Training Discriminator : ')\n",
    "    train_discriminator(dis, dis_optimizer, trainset_tensor, gen, trainset, d_steps, 3)\n",
    "    \n",
    "    # Generate seqGAN samples\n",
    "    path='output/seqGAN-epoch{}.samples'.format(epoch)\n",
    "    generateSamples(gen, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqgan_gen_path = './gen_seqgan_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "torch.save(gen.state_dict(), seqgan_gen_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Perplexity On The seqGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15092/15092 [03:06<00:00, 80.92it/s]\n"
     ]
    }
   ],
   "source": [
    "path='./dataset/test.vec'\n",
    "ppl=calculatePPL(gen, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.36233806646914"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Perplexity On The seqGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15092/15092 [03:18<00:00, 76.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52.23670100370715"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.load_state_dict(torch.load(pretrained_gen_path))\n",
    "path='./dataset/test.vec'\n",
    "ppl=calculatePPL(gen, path)\n",
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LSTM samples\n",
    "gen.load_state_dict(torch.load(seqgan_gen_path))\n",
    "\n",
    "path='output/seqgan.samples'\n",
    "generateSamples(gen, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
